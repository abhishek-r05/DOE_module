{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> doeMain </h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> doeMain is the package which helps in creating the design space for the experiments. This package consists of four classes. These are listed below:<p>\n",
    "<p>\n",
    "* doeMaster (Parent)\n",
    "* pyDOEMaster (Child)\n",
    "* diversipyMaster (Child)\n",
    "\n",
    "<p> The usage of these classes as well as the sample outputs are mentioned in this notebook. <p> \n",
    "<p> There are three packages available in doeMain: <p>\n",
    "* pyDOE \n",
    "* diversipy\n",
    "\n",
    "<p> The contents of the classes are as mentioned below: <p>\n",
    "\n",
    "<p>1. doeMaster\n",
    "<ol>\n",
    "    <li> Packages available </li>\n",
    "    <li> LHS Correlation Score </li>\n",
    "    <li> LHS Distance Score </li>\n",
    "    <li> Input Distribution Types and functions </li>\n",
    "    <li> Applying Distributions </li>\n",
    "    <li> Slicing down the matrix </li>\n",
    "    <li> Plotting the matrix </li>\n",
    "    <li> Adding new samples to the existing matrix </li>\n",
    "</ol>    \n",
    "<p>2. pyDOEMaster\n",
    "<ol>\n",
    "    <li> Creating LHS </li>\n",
    "</ol>    \n",
    "<p>3. diversipyMaster\n",
    "<ol>\n",
    "    <li> Converting Co-ordinates to Unit Hypercube </li>\n",
    "    <li> Creating LHD Matrix </li>\n",
    "    <li> Improving the existing LHD Matrix </li>\n",
    "    <li> Sliced LHS Matrix </li>\n",
    "</ol>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> For importing any package, a path must set to access the directories. This can be done as shown below. <p> \n",
    "* os.chdir() is used to set the location where these packages are existing. \n",
    "* os.getcwd() helps in getting the current working directory location where the path has been assigned to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ra2\\Documents\\Python_Scripts\\ExcelADE\\FinalModule\n"
     ]
    }
   ],
   "source": [
    "# Importing supporting modules for Notebook.\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "print(os.getcwd())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Any information about the package or module can be accessed using help function as shown below. It invokes the built-in help system. If no argument is given, the interactive help system starts on the interpreter console.  <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module doeModule.doeMain in doeModule:\n",
      "\n",
      "NAME\n",
      "    doeModule.doeMain\n",
      "\n",
      "FILE\n",
      "    c:\\users\\ra2\\documents\\python_scripts\\excelade\\finalmodule\\doemodule\\doemain.py\n",
      "\n",
      "CLASSES\n",
      "    __builtin__.object\n",
      "        doeMaster\n",
      "            dakotaMaster\n",
      "            diversipyMaster\n",
      "            pyDOEMaster\n",
      "    \n",
      "    class dakotaMaster(doeMaster)\n",
      "     |  Child Class of doeMaster, for Dakota Packages\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      dakotaMaster\n",
      "     |      doeMaster\n",
      "     |      __builtin__.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize the class dakotaMaster\n",
      "     |  \n",
      "     |  getActualSamples(self, nParams, nMinSamples)\n",
      "     |          Get the Actual no of sample for OA-LHS methods\n",
      "     |      :param nParams: No of input Parameters/ inputs\n",
      "     |      :param nMinSamples: Min Samples needed\n",
      "     |      :return:\n",
      "     |          nActualSamples\n",
      "     |  \n",
      "     |  incrementalLHS(self)\n",
      "     |          The incremental LHS can only be called if you have already created DOE using any of the dakota library\n",
      "     |          function\n",
      "     |      :param nSamples: How many more samples do you want?\n",
      "     |      \n",
      "     |      :return:\n",
      "     |          DOE matrix\n",
      "     |  \n",
      "     |  lhs(self, nInputs=None, nSamples=None, inputDistribution=None, useLastSeed=False, addDiscreteVars=[])\n",
      "     |          Calls the lhs method under sampling of dakota libraries to create the DOE. Also supported sliced DOE\n",
      "     |          creation for discrete variables.\n",
      "     |      \n",
      "     |          NOTE:\n",
      "     |              1. dakota files are create under subfolder wrt pwd (./dakotaTemp/) as default.\n",
      "     |              2. obj.setDakotaTempPath(path) function can be used if you want to use new directory.\n",
      "     |              3. input file, output file, doe file are defaulted to 'dakota_model.in','dakota_model.out','doe_out.dat'\n",
      "     |              4. input file, output file, doe file can be modified if you change the class variable\n",
      "     |                  obj.doeModelInFile,obj.doeModelOutFile,obj.doeGraphicName\n",
      "     |              5. All continous variables are create by default uniform(0,1) inside dakota.\n",
      "     |              6. Converting them to corresponding distribution is handled outside of dakota libraries.\n",
      "     |      \n",
      "     |      :param nInputs:\n",
      "     |          No of inputs/Parameters for continuous type to be created\n",
      "     |      :param nSamples:\n",
      "     |          No of sample points for creating the LHS\n",
      "     |      :param inputDistribution:\n",
      "     |          Default 'None' : all input are create in range of 0-1 [unit Hypercube]\n",
      "     |          You can also choose different input distributions example [['uniform',0,10]] ranging from 0-10 with equal probability.\n",
      "     |          Check function getInputDistributionTypes() to find all options\n",
      "     |      :param useLastSeed:\n",
      "     |          If you want to use the same seed value as used in last run.\n",
      "     |      :param addDiscreteVars\n",
      "     |          Should be a list of list each sublist containing possible values of the discreate variable\n",
      "     |          example [['high','low','medium'],['uphill','downhill']] corresponds to 2 discreate variables with 3/2\n",
      "     |          possible values\n",
      "     |          NOTE : nInputs parameter does not include the count of discreate variables\n",
      "     |      :return:\n",
      "     |          returns lhs matrix\n",
      "     |  \n",
      "     |  oaLHS(self, nInputs=None, nSamples=None, inputDistribution=None, useLastSeed=False, addDiscreteVars=[])\n",
      "     |          Calls the lhs method under sampling of dakota libraries to create the DOE. Also supported sliced DOE\n",
      "     |          creation for discrete variables.\n",
      "     |      \n",
      "     |          NOTE:\n",
      "     |              1. dakota files are create under subfolder wrt pwd (./dakotaTemp/) as default.\n",
      "     |              2. obj.setDakotaTempPath(path) function can be used if you want to use new directory.\n",
      "     |              3. input file, output file, doe file are defaulted to 'dakota_model.in','dakota_model.out','doe_out.dat'\n",
      "     |              4. input file, output file, doe file can be modified if you change the class variable\n",
      "     |                  obj.doeModelInFile,obj.doeModelOutFile,obj.doeGraphicName\n",
      "     |              5. All continous variables are create by default uniform(0,1) inside dakota.\n",
      "     |              6. Converting them to corresponding distribution is handled outside of dakota libraries.\n",
      "     |      \n",
      "     |      :param nInputs:\n",
      "     |          No of inputs/Parameters for continuous type to be created\n",
      "     |      :param nSamples:\n",
      "     |          No of sample points for creating the LHS\n",
      "     |      :param inputDistribution:\n",
      "     |          Default 'None' : all input are create in range of 0-1 [unit Hypercube]\n",
      "     |          You can also choose different input distributions example [['uniform',0,10]] ranging from 0-10 with equal probability.\n",
      "     |          Check function getInputDistributionTypes() to find all options\n",
      "     |      :param useLastSeed:\n",
      "     |          If you want to use the same seed value as used in last run.\n",
      "     |      :param addDiscreteVars\n",
      "     |          Should be a list of list each sublist containing possible values of the discreate variable\n",
      "     |          example [['high','low','medium'],['uphill','downhill']] corresponds to 2 discreate variables with 3/2\n",
      "     |          possible values\n",
      "     |          NOTE : nInputs parameter does not include the count of discreate variables\n",
      "     |      :return:\n",
      "     |          returns lhs matrix\n",
      "     |  \n",
      "     |  setDakotaTempPath(self, path)\n",
      "     |          Setting the path for storing dakota related files.\n",
      "     |      :param path:\n",
      "     |          The path where all dakota file will be stored\n",
      "     |      :return:\n",
      "     |  \n",
      "     |  slicedLHS(self, nInputs=None, nSamples=None, nSlice=2, inputDistribution=None, useLastSeed=False, addDiscreteVars=[])\n",
      "     |          This Method creates sliced LHS using dakota functions\n",
      "     |      \n",
      "     |      :param nInputs:\n",
      "     |          No of inputs/Parameters for continuous type to be created\n",
      "     |      :param nSamples:\n",
      "     |          No of sample points per sliced LHS\n",
      "     |      :param nSlice:\n",
      "     |          No of Slices you want to create.\n",
      "     |      :param inputDistribution:\n",
      "     |          Default 'None' : all input are create in range of 0-1 [unit Hypercube]\n",
      "     |          You can also choose different input distributions example [['uniform',0,10]] ranging from 0-10 with equal probability.\n",
      "     |          Check function getInputDistributionTypes() to find all options\n",
      "     |      :param useLastSeed:\n",
      "     |          If you want to use the same seed value as used in last run.\n",
      "     |      :param addDiscreteVars\n",
      "     |          Should be a list of list each sublist containing possible values of the discreate variable\n",
      "     |          example [['high','low','medium'],['uphill','downhill']] corresponds to 2 discreate variables with 3/2\n",
      "     |          possible values\n",
      "     |          NOTE : nInputs parameter does not include the count of discreate variables\n",
      "     |      :return:\n",
      "     |          A dictionary with sliced LHS matrix\n",
      "     |          examples {'Slice_1': matrix,'Slice_2': matrix ...}\n",
      "     |  \n",
      "     |  writeInFile(self, addDiscreteVars=[])\n",
      "     |          Creates the .IN file for dakota, nothing fancy create it by hardcoding most stuff.\n",
      "     |          In case additional methods gets added. The format needs to be revised.\n",
      "     |      :return:\n",
      "     |          status : True/False for sucess/failure\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from doeMaster:\n",
      "     |  \n",
      "     |  addNpointsLHS(self, inMatrix, m=1, method='random')\n",
      "     |      Add 'n' new points to the existing LHS matrix.\n",
      "     |      NOTE:\n",
      "     |          Assumes inMatrix to be a unit Hypercube i.e. all parameters are from 0-1\n",
      "     |      :param m:\n",
      "     |          How many new points do you want.\n",
      "     |      :param method:\n",
      "     |          'random' : choose a random value inside the bin\n",
      "     |          'center' : choose the mid point of the bin\n",
      "     |      :return:\n",
      "     |  \n",
      "     |  applyDistributionToMatrix(self, inMatrix, inDistribution)\n",
      "     |      Takes in the input unitMatrix and multiple with the respective distribution given by inDistribution.\n",
      "     |      :param inMatrix:\n",
      "     |      input unit hypercube matrix\n",
      "     |      :param inDistribution:\n",
      "     |          list of list each sublist if cooresponding the the ith input and contains the necessary information\n",
      "     |          about the input\n",
      "     |      :return:\n",
      "     |          return the updated matrix wrt input distribution provided.\n",
      "     |  \n",
      "     |  getInputDistributionFunction(self, params)\n",
      "     |      This create a ppf function for the specified distribution and return it, this can then be multiplied with\n",
      "     |      the matrix column to convert it.\n",
      "     |      :param params:\n",
      "     |          each param should be of format ['type',p1,p2..] p1,p2 corresponds to the input of 'type' of distribution\n",
      "     |          you select.\n",
      "     |      :return:\n",
      "     |          ppf function.\n",
      "     |  \n",
      "     |  getInputDistributionTypes(self)\n",
      "     |      :return:\n",
      "     |          List of all supported distribution\n",
      "     |  \n",
      "     |  lhsCorrScore(self, inputMatrix)\n",
      "     |      This Function Calculate the correlation between each columns of the input matrix.\n",
      "     |      Calculates RHO as a score of correlation\n",
      "     |      \n",
      "     |      :param input_matrix:\n",
      "     |          Input Matrix for which the score has to be calculated.\n",
      "     |      :return:\n",
      "     |          rho,maxPairwiseCorr,corrMatrix\n",
      "     |  \n",
      "     |  lhsDistScore(self, inputMatrix)\n",
      "     |      This Function Calculate the L1 and L2 distrance between each row of the input matrix.\n",
      "     |      :param inputMatrix:\n",
      "     |          Input Matrix for which the score has to be calculated.\n",
      "     |      :return:\n",
      "     |          mean L1 distance,mean L2 distance\n",
      "     |  \n",
      "     |  listPackages(self)\n",
      "     |      Can be used to view all the eligible packages.\n",
      "     |      NOTE : Dakota installation is not validation.\n",
      "     |      :return: List of Available Packages\n",
      "     |  \n",
      "     |  plotMatrix(self, inputMatrix, addGrid=False, nNewPoints=None, figsize=(20, 20))\n",
      "     |          Function to be used to view the DOE distribution in 2D plane (wrt each column pairs)\n",
      "     |      :param inputMatrix: Input Matrix which needs to be plotted. In case of sliced DOE it should be dictionary\n",
      "     |          containing matrix for each slice.\n",
      "     |      :param addGrid: Add grid only works for unit hypercube. Set true to add it\n",
      "     |      :param nNewPoints: Setting this to numeric value will color the n points from the end of the array to red color\n",
      "     |      :param figsize: provide a tuple for plot size.\n",
      "     |      :return: None\n",
      "     |  \n",
      "     |  setPackage(self, packageName)\n",
      "     |      Select the wrapper class corresponding to the package name.\n",
      "     |      :param packageName:\n",
      "     |          Provide package name, use listPackages() to get the list of available packages\n",
      "     |      :return:\n",
      "     |          object of the Wrapper Class corresponding to the input package name, error string incase of invalid package\n",
      "     |  \n",
      "     |  sliceDOE(self, inMatrix)\n",
      "     |          This function takes the inMatrix seperates continuous variables and discrete variables.\n",
      "     |          For each unique value of discrete columns stores the subset matrix of continuous variables in a dictionary\n",
      "     |          and returns it.\n",
      "     |          NOTE: Discrete columns is identified if they have string value.\n",
      "     |          Columns with numeric value 1,2,3 will not be treated ad discrete. It has to be '1','2','3'\n",
      "     |      \n",
      "     |      :param inMatrix:\n",
      "     |          Input matrix containing discrete variables which needs to be sliced.\n",
      "     |      \n",
      "     |      :return:\n",
      "     |          dictionary containing slices wrt each discrete value\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from doeMaster:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class diversipyMaster(doeMaster)\n",
      "     |  Child Class of doeMaster, for python Package diversipy\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      diversipyMaster\n",
      "     |      doeMaster\n",
      "     |      __builtin__.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initilize diversipyMaster Class\n",
      "     |  \n",
      "     |  convertCoordinateToUnitHypercube(self, inMatrix, method='center')\n",
      "     |          diversipyMaster libraries always return the LHS as coordinate based values.\n",
      "     |          We need to convert then to actual values from 0-1.\n",
      "     |      :param inMatrix:\n",
      "     |          inMatrix is lhs matrix with coordinates corresponding to the bins\n",
      "     |      :param method:\n",
      "     |          For each bin how should the point be selected. You have 3 options:\n",
      "     |          1. 'center' : select the mid point of each bin\n",
      "     |          2. 'random' : select random point inside each bin\n",
      "     |          3. 'max_distance' : select the point such that all bins are far apart.\n",
      "     |      :return:\n",
      "     |          matrix with updated values.\n",
      "     |  \n",
      "     |  improved_lhd_matrix(self, nInputs=None, nSamples=None, inputDistribution=None, selectPointMethod='center', num_candidates=100, target_value=None)\n",
      "     |          calls the improved_lhs_matrix function from the diversipy library\n",
      "     |      :param nInputs:\n",
      "     |          No of inputs/Parameters for creating the LHS\n",
      "     |      :param nSamples:\n",
      "     |          No of sample points for creating the LHS\n",
      "     |      :param inputDistribution:\n",
      "     |          Default 'None' : all input are create in range of 0-1 [unit Hypercube]\n",
      "     |          You can also choose different input distributions example [['uniform',0,10]] ranging from 0-10 with equal probability.\n",
      "     |          Check function getInputDistributionTypes() to find all options\n",
      "     |      :param selectPointMethod:\n",
      "     |          For each bin how should the point be selected. You have 3 options:\n",
      "     |          1. 'center' : select the mid point of each bin\n",
      "     |          2. 'random' : select random point inside each bin\n",
      "     |          3. 'max_distance' : select the point such that all bins are far apart.\n",
      "     |      :param num_candidates:\n",
      "     |          default is 100.\n",
      "     |          The number of random candidates considered for every point to be added to the LHD\n",
      "     |      :param target_value:\n",
      "     |          default is None\n",
      "     |          The distance a candidate should ideally have to the already chosen points of the LHD.\n",
      "     |      :return:\n",
      "     |          lhs Matrix\n",
      "     |  \n",
      "     |  lhd_matrix(self, nInputs=None, nSamples=None, inputDistribution=None, selectPointMethod='center')\n",
      "     |          Calls the lhs_matrix function from diversipy package to create the LHS\n",
      "     |          :param nInputs:\n",
      "     |          No of inputs/Parameters for creating the LHS\n",
      "     |      :param nSamples:\n",
      "     |          No of sample points for creating the LHS\n",
      "     |      :param inputDistribution:\n",
      "     |          Default 'None' : all input are create in range of 0-1 [unit Hypercube]\n",
      "     |          You can also choose different input distributions example [['uniform',0,10]] ranging from 0-10 with equal probability.\n",
      "     |          Check function getInputDistributionTypes() to find all options\n",
      "     |      :param selectPointMethod:\n",
      "     |          For each bin how should the point be selected. You have 3 options:\n",
      "     |          1. 'center' : select the mid point of each bin\n",
      "     |          2. 'random' : select random point inside each bin\n",
      "     |          3. 'max_distance' : select the point such that all bins are far apart.\n",
      "     |      \n",
      "     |      :return:\n",
      "     |          return the matrix of LHS create by the method.\n",
      "     |  \n",
      "     |  slicedLHS(self, nInputs=None, nSamples=None, nSlice=2, inputDistribution=None, selectPointMethod='center', num_candidates=100, target_value=None)\n",
      "     |          This Method creates sliced LHS using diversipy liraries\n",
      "     |      \n",
      "     |      :param nInputs:\n",
      "     |          No of inputs/Parameters for continuous type to be created\n",
      "     |      :param nSamples:\n",
      "     |          No of sample points per sliced LHS\n",
      "     |      :param nSlice:\n",
      "     |          No of Slices you want to create.\n",
      "     |      :param inputDistribution:\n",
      "     |          Default 'None' : all input are create in range of 0-1 [unit Hypercube]\n",
      "     |          You can also choose different input distributions example [['uniform',0,10]] ranging from 0-10 with equal probability.\n",
      "     |          Check function getInputDistributionTypes() to find all options\n",
      "     |      :param selectPointMethod:\n",
      "     |          For each bin how should the point be selected. You have 3 options:\n",
      "     |          1. 'center' : select the mid point of each bin\n",
      "     |          2. 'random' : select random point inside each bin\n",
      "     |          3. 'max_distance' : select the point such that all bins are far apart.\n",
      "     |      :param num_candidates:\n",
      "     |          default is 100.\n",
      "     |          The number of random candidates considered for every point to be added to the LHD\n",
      "     |      :param target_value:\n",
      "     |          default is None\n",
      "     |          The distance a candidate should ideally have to the already chosen points of the LHD.\n",
      "     |      :return:\n",
      "     |          A dictionary with sliced LHS matrix\n",
      "     |          examples {'Slice_1': matrix,'Slice_2': matrix ...}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from doeMaster:\n",
      "     |  \n",
      "     |  addNpointsLHS(self, inMatrix, m=1, method='random')\n",
      "     |      Add 'n' new points to the existing LHS matrix.\n",
      "     |      NOTE:\n",
      "     |          Assumes inMatrix to be a unit Hypercube i.e. all parameters are from 0-1\n",
      "     |      :param m:\n",
      "     |          How many new points do you want.\n",
      "     |      :param method:\n",
      "     |          'random' : choose a random value inside the bin\n",
      "     |          'center' : choose the mid point of the bin\n",
      "     |      :return:\n",
      "     |  \n",
      "     |  applyDistributionToMatrix(self, inMatrix, inDistribution)\n",
      "     |      Takes in the input unitMatrix and multiple with the respective distribution given by inDistribution.\n",
      "     |      :param inMatrix:\n",
      "     |      input unit hypercube matrix\n",
      "     |      :param inDistribution:\n",
      "     |          list of list each sublist if cooresponding the the ith input and contains the necessary information\n",
      "     |          about the input\n",
      "     |      :return:\n",
      "     |          return the updated matrix wrt input distribution provided.\n",
      "     |  \n",
      "     |  getInputDistributionFunction(self, params)\n",
      "     |      This create a ppf function for the specified distribution and return it, this can then be multiplied with\n",
      "     |      the matrix column to convert it.\n",
      "     |      :param params:\n",
      "     |          each param should be of format ['type',p1,p2..] p1,p2 corresponds to the input of 'type' of distribution\n",
      "     |          you select.\n",
      "     |      :return:\n",
      "     |          ppf function.\n",
      "     |  \n",
      "     |  getInputDistributionTypes(self)\n",
      "     |      :return:\n",
      "     |          List of all supported distribution\n",
      "     |  \n",
      "     |  lhsCorrScore(self, inputMatrix)\n",
      "     |      This Function Calculate the correlation between each columns of the input matrix.\n",
      "     |      Calculates RHO as a score of correlation\n",
      "     |      \n",
      "     |      :param input_matrix:\n",
      "     |          Input Matrix for which the score has to be calculated.\n",
      "     |      :return:\n",
      "     |          rho,maxPairwiseCorr,corrMatrix\n",
      "     |  \n",
      "     |  lhsDistScore(self, inputMatrix)\n",
      "     |      This Function Calculate the L1 and L2 distrance between each row of the input matrix.\n",
      "     |      :param inputMatrix:\n",
      "     |          Input Matrix for which the score has to be calculated.\n",
      "     |      :return:\n",
      "     |          mean L1 distance,mean L2 distance\n",
      "     |  \n",
      "     |  listPackages(self)\n",
      "     |      Can be used to view all the eligible packages.\n",
      "     |      NOTE : Dakota installation is not validation.\n",
      "     |      :return: List of Available Packages\n",
      "     |  \n",
      "     |  plotMatrix(self, inputMatrix, addGrid=False, nNewPoints=None, figsize=(20, 20))\n",
      "     |          Function to be used to view the DOE distribution in 2D plane (wrt each column pairs)\n",
      "     |      :param inputMatrix: Input Matrix which needs to be plotted. In case of sliced DOE it should be dictionary\n",
      "     |          containing matrix for each slice.\n",
      "     |      :param addGrid: Add grid only works for unit hypercube. Set true to add it\n",
      "     |      :param nNewPoints: Setting this to numeric value will color the n points from the end of the array to red color\n",
      "     |      :param figsize: provide a tuple for plot size.\n",
      "     |      :return: None\n",
      "     |  \n",
      "     |  setPackage(self, packageName)\n",
      "     |      Select the wrapper class corresponding to the package name.\n",
      "     |      :param packageName:\n",
      "     |          Provide package name, use listPackages() to get the list of available packages\n",
      "     |      :return:\n",
      "     |          object of the Wrapper Class corresponding to the input package name, error string incase of invalid package\n",
      "     |  \n",
      "     |  sliceDOE(self, inMatrix)\n",
      "     |          This function takes the inMatrix seperates continuous variables and discrete variables.\n",
      "     |          For each unique value of discrete columns stores the subset matrix of continuous variables in a dictionary\n",
      "     |          and returns it.\n",
      "     |          NOTE: Discrete columns is identified if they have string value.\n",
      "     |          Columns with numeric value 1,2,3 will not be treated ad discrete. It has to be '1','2','3'\n",
      "     |      \n",
      "     |      :param inMatrix:\n",
      "     |          Input matrix containing discrete variables which needs to be sliced.\n",
      "     |      \n",
      "     |      :return:\n",
      "     |          dictionary containing slices wrt each discrete value\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from doeMaster:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class doeMaster(__builtin__.object)\n",
      "     |  Main Class For all DOEs.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Intialize the method available to doeMaster class.\n",
      "     |  \n",
      "     |  addNpointsLHS(self, inMatrix, m=1, method='random')\n",
      "     |      Add 'n' new points to the existing LHS matrix.\n",
      "     |      NOTE:\n",
      "     |          Assumes inMatrix to be a unit Hypercube i.e. all parameters are from 0-1\n",
      "     |      :param m:\n",
      "     |          How many new points do you want.\n",
      "     |      :param method:\n",
      "     |          'random' : choose a random value inside the bin\n",
      "     |          'center' : choose the mid point of the bin\n",
      "     |      :return:\n",
      "     |  \n",
      "     |  applyDistributionToMatrix(self, inMatrix, inDistribution)\n",
      "     |      Takes in the input unitMatrix and multiple with the respective distribution given by inDistribution.\n",
      "     |      :param inMatrix:\n",
      "     |      input unit hypercube matrix\n",
      "     |      :param inDistribution:\n",
      "     |          list of list each sublist if cooresponding the the ith input and contains the necessary information\n",
      "     |          about the input\n",
      "     |      :return:\n",
      "     |          return the updated matrix wrt input distribution provided.\n",
      "     |  \n",
      "     |  getInputDistributionFunction(self, params)\n",
      "     |      This create a ppf function for the specified distribution and return it, this can then be multiplied with\n",
      "     |      the matrix column to convert it.\n",
      "     |      :param params:\n",
      "     |          each param should be of format ['type',p1,p2..] p1,p2 corresponds to the input of 'type' of distribution\n",
      "     |          you select.\n",
      "     |      :return:\n",
      "     |          ppf function.\n",
      "     |  \n",
      "     |  getInputDistributionTypes(self)\n",
      "     |      :return:\n",
      "     |          List of all supported distribution\n",
      "     |  \n",
      "     |  lhsCorrScore(self, inputMatrix)\n",
      "     |      This Function Calculate the correlation between each columns of the input matrix.\n",
      "     |      Calculates RHO as a score of correlation\n",
      "     |      \n",
      "     |      :param input_matrix:\n",
      "     |          Input Matrix for which the score has to be calculated.\n",
      "     |      :return:\n",
      "     |          rho,maxPairwiseCorr,corrMatrix\n",
      "     |  \n",
      "     |  lhsDistScore(self, inputMatrix)\n",
      "     |      This Function Calculate the L1 and L2 distrance between each row of the input matrix.\n",
      "     |      :param inputMatrix:\n",
      "     |          Input Matrix for which the score has to be calculated.\n",
      "     |      :return:\n",
      "     |          mean L1 distance,mean L2 distance\n",
      "     |  \n",
      "     |  listPackages(self)\n",
      "     |      Can be used to view all the eligible packages.\n",
      "     |      NOTE : Dakota installation is not validation.\n",
      "     |      :return: List of Available Packages\n",
      "     |  \n",
      "     |  plotMatrix(self, inputMatrix, addGrid=False, nNewPoints=None, figsize=(20, 20))\n",
      "     |          Function to be used to view the DOE distribution in 2D plane (wrt each column pairs)\n",
      "     |      :param inputMatrix: Input Matrix which needs to be plotted. In case of sliced DOE it should be dictionary\n",
      "     |          containing matrix for each slice.\n",
      "     |      :param addGrid: Add grid only works for unit hypercube. Set true to add it\n",
      "     |      :param nNewPoints: Setting this to numeric value will color the n points from the end of the array to red color\n",
      "     |      :param figsize: provide a tuple for plot size.\n",
      "     |      :return: None\n",
      "     |  \n",
      "     |  setPackage(self, packageName)\n",
      "     |      Select the wrapper class corresponding to the package name.\n",
      "     |      :param packageName:\n",
      "     |          Provide package name, use listPackages() to get the list of available packages\n",
      "     |      :return:\n",
      "     |          object of the Wrapper Class corresponding to the input package name, error string incase of invalid package\n",
      "     |  \n",
      "     |  sliceDOE(self, inMatrix)\n",
      "     |          This function takes the inMatrix seperates continuous variables and discrete variables.\n",
      "     |          For each unique value of discrete columns stores the subset matrix of continuous variables in a dictionary\n",
      "     |          and returns it.\n",
      "     |          NOTE: Discrete columns is identified if they have string value.\n",
      "     |          Columns with numeric value 1,2,3 will not be treated ad discrete. It has to be '1','2','3'\n",
      "     |      \n",
      "     |      :param inMatrix:\n",
      "     |          Input matrix containing discrete variables which needs to be sliced.\n",
      "     |      \n",
      "     |      :return:\n",
      "     |          dictionary containing slices wrt each discrete value\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class pyDOEMaster(doeMaster)\n",
      "     |  Child Class of doeMaster, for python Package pyDOE\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      pyDOEMaster\n",
      "     |      doeMaster\n",
      "     |      __builtin__.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize the pyDOEMaster Class\n",
      "     |  \n",
      "     |  lhs(self, nInputs=None, nSamples=None, inputDistribution=None, criterion='corr')\n",
      "     |      :param nInputs:\n",
      "     |          No of inputs/Parameters for creating the LHS\n",
      "     |      :param nSamples:\n",
      "     |          No of sample points for creating the LHS\n",
      "     |      :param inputDistribution:\n",
      "     |          Default 'None' : all input are create in range of 0-1 [unit Hypercube]\n",
      "     |          You can also choose different input distributions example [['uniform',0,10]] ranging from 0-10 with equal probability.\n",
      "     |          Check function getInputDistributionTypes() to find all options\n",
      "     |      :param criterion:\n",
      "     |          default : 'corr'\n",
      "     |          'c': center the points within the sampling intervals\n",
      "     |          'm': maximize the minimum distance between points, but place the point in a randomized location within its interval\n",
      "     |          'cm': same as 'm' but centered within the intervals\n",
      "     |          'corr': minimize the maximum correlation coefficient\n",
      "     |      :return:\n",
      "     |          return the lhs matrix\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from doeMaster:\n",
      "     |  \n",
      "     |  addNpointsLHS(self, inMatrix, m=1, method='random')\n",
      "     |      Add 'n' new points to the existing LHS matrix.\n",
      "     |      NOTE:\n",
      "     |          Assumes inMatrix to be a unit Hypercube i.e. all parameters are from 0-1\n",
      "     |      :param m:\n",
      "     |          How many new points do you want.\n",
      "     |      :param method:\n",
      "     |          'random' : choose a random value inside the bin\n",
      "     |          'center' : choose the mid point of the bin\n",
      "     |      :return:\n",
      "     |  \n",
      "     |  applyDistributionToMatrix(self, inMatrix, inDistribution)\n",
      "     |      Takes in the input unitMatrix and multiple with the respective distribution given by inDistribution.\n",
      "     |      :param inMatrix:\n",
      "     |      input unit hypercube matrix\n",
      "     |      :param inDistribution:\n",
      "     |          list of list each sublist if cooresponding the the ith input and contains the necessary information\n",
      "     |          about the input\n",
      "     |      :return:\n",
      "     |          return the updated matrix wrt input distribution provided.\n",
      "     |  \n",
      "     |  getInputDistributionFunction(self, params)\n",
      "     |      This create a ppf function for the specified distribution and return it, this can then be multiplied with\n",
      "     |      the matrix column to convert it.\n",
      "     |      :param params:\n",
      "     |          each param should be of format ['type',p1,p2..] p1,p2 corresponds to the input of 'type' of distribution\n",
      "     |          you select.\n",
      "     |      :return:\n",
      "     |          ppf function.\n",
      "     |  \n",
      "     |  getInputDistributionTypes(self)\n",
      "     |      :return:\n",
      "     |          List of all supported distribution\n",
      "     |  \n",
      "     |  lhsCorrScore(self, inputMatrix)\n",
      "     |      This Function Calculate the correlation between each columns of the input matrix.\n",
      "     |      Calculates RHO as a score of correlation\n",
      "     |      \n",
      "     |      :param input_matrix:\n",
      "     |          Input Matrix for which the score has to be calculated.\n",
      "     |      :return:\n",
      "     |          rho,maxPairwiseCorr,corrMatrix\n",
      "     |  \n",
      "     |  lhsDistScore(self, inputMatrix)\n",
      "     |      This Function Calculate the L1 and L2 distrance between each row of the input matrix.\n",
      "     |      :param inputMatrix:\n",
      "     |          Input Matrix for which the score has to be calculated.\n",
      "     |      :return:\n",
      "     |          mean L1 distance,mean L2 distance\n",
      "     |  \n",
      "     |  listPackages(self)\n",
      "     |      Can be used to view all the eligible packages.\n",
      "     |      NOTE : Dakota installation is not validation.\n",
      "     |      :return: List of Available Packages\n",
      "     |  \n",
      "     |  plotMatrix(self, inputMatrix, addGrid=False, nNewPoints=None, figsize=(20, 20))\n",
      "     |          Function to be used to view the DOE distribution in 2D plane (wrt each column pairs)\n",
      "     |      :param inputMatrix: Input Matrix which needs to be plotted. In case of sliced DOE it should be dictionary\n",
      "     |          containing matrix for each slice.\n",
      "     |      :param addGrid: Add grid only works for unit hypercube. Set true to add it\n",
      "     |      :param nNewPoints: Setting this to numeric value will color the n points from the end of the array to red color\n",
      "     |      :param figsize: provide a tuple for plot size.\n",
      "     |      :return: None\n",
      "     |  \n",
      "     |  setPackage(self, packageName)\n",
      "     |      Select the wrapper class corresponding to the package name.\n",
      "     |      :param packageName:\n",
      "     |          Provide package name, use listPackages() to get the list of available packages\n",
      "     |      :return:\n",
      "     |          object of the Wrapper Class corresponding to the input package name, error string incase of invalid package\n",
      "     |  \n",
      "     |  sliceDOE(self, inMatrix)\n",
      "     |          This function takes the inMatrix seperates continuous variables and discrete variables.\n",
      "     |          For each unique value of discrete columns stores the subset matrix of continuous variables in a dictionary\n",
      "     |          and returns it.\n",
      "     |          NOTE: Discrete columns is identified if they have string value.\n",
      "     |          Columns with numeric value 1,2,3 will not be treated ad discrete. It has to be '1','2','3'\n",
      "     |      \n",
      "     |      :param inMatrix:\n",
      "     |          Input matrix containing discrete variables which needs to be sliced.\n",
      "     |      \n",
      "     |      :return:\n",
      "     |          dictionary containing slices wrt each discrete value\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from doeMaster:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from doeModule import doeMain\n",
    "help(doeMain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1. doeMaster <h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Calling the Module <h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> doeMaster is the parent classes  having child class (pyDOEMaster,dakotaMaster,diversipyMaster) The following functions are supported in the doeMaster class, these methods can also be accessed from the child class <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# doeMaster \n",
    "doeMasterObj = doeMain.doeMaster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> 1.1 Packages available <h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Listing down the available packages </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> doeMaster contains 3 packages. The list of all the packages available can be listed down by using the below code. The three packages which are available as of now are 'dakota', 'pyDOE' and 'diversipy' <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dakota', 'pyDOE', 'diversipy']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_packages = doeMasterObj.listPackages()\n",
    "available_packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Selecting the desired package<h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> The desired package, which are mentioned in the package list can be set for the further validation process. It can be set as doeMaster.setPackage('Package'). The available packages are 'dakota', 'pyDOE' and 'diversipy' <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyDOEMasterObj = doeMasterObj.setPackage('pyDOE')\n",
    "\n",
    "# ALTERNATIVELY you can also create the object directly.\n",
    "# From subfolder doeModule get import class pyDOEMaster from doeMain.py\n",
    "from doeModule.doeMain import pyDOEMaster\n",
    "\n",
    "# Create a object, to Use the function of the Class.\n",
    "pyDOEMasterObj = pyDOEMaster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new candidate solution found with max,abs corrcoef = 0.93514022792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.55692818,  0.47897811,  0.32274111],\n",
       "       [ 0.30193311,  0.29022724,  0.64313116],\n",
       "       [ 0.76786446,  0.88234796,  0.77209627]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a simple LHS\n",
    "matrix_created  = pyDOEMasterObj.lhs(nInputs = 3, nSamples = 3)\n",
    "matrix_created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Supporing Function For created Matrix</h4>\n",
    "<p>We will be using the above created matrix to show example of supporting functions.\n",
    "Later we will see, multiple ways of creating LHS matrix using various packages we have</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>1.2 LHS Correlation Score <h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_doeMaster.lhsCorrScore(inputMatrix)_** \n",
    "<p> This function calculates the correlation across the columns of a given matrix. Correlation represents the linear association between two vectors. The given function takes the input as a matrix and returns the correlation score across the columns as a Correlation Table. It also prints the \"Rho\" and the maximum pairwise correlation value of a given matrix <p>\n",
    "<p> The input parameters for obtaining these correlation values should be in the form of a matrix. The below snippet shows how to obtain the correlation values out of a given input matrix <p> \n",
    "<p> The Correlation Table is the table containing Pearson product moment correlation co-efficients. The correlation table is obtained as <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\ R_(i,j) = \\frac {C_(i,j)} {\\sqrt{C_(i,i)} \\times \\sqrt{C_(j,j)}}\n",
    "\\end{equation*}\n",
    "<p>R : Correlation Co-efficient matrix<p> \n",
    "<p>C : Covariance Matrix<p>\n",
    "<p> The Parameters that need to be given as input to this function are:\n",
    "* inputMatrix : The matrix for which the Correlation scores need to calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** RHO ***\n",
      "0.633763704806\n",
      "*** Max Pairwise Correlation ***\n",
      "0.96617654816\n",
      "*** Correlation Table ***\n",
      "[[        nan  0.96617655  0.22592677]\n",
      " [ 0.96617655         nan  0.46949896]\n",
      " [ 0.22592677  0.46949896         nan]]\n"
     ]
    }
   ],
   "source": [
    "corr_score = doeMasterObj.lhsCorrScore(matrix_created)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>1.3 LHS Distance Score <h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_doeMaster.lhsDistScore(inputMatrix)_**\n",
    "<p> This function calculates the distance across the rows. This calculation is done in two norms, L1 - norm and L2 - norm. <p>\n",
    "<p> *  L1 norm - It gives the absolute distance<p>\n",
    "<p> *  L2 norm - It gives the least squares distance <p>\n",
    "<p> The input parameters for this function are: <p>\n",
    "* inputMatrix : The for which the score has to be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** L1 Distance ***\n",
      "Mean =  1.00493815155\n",
      "Max =  1.18701717766\n",
      "Min =  0.764135988681\n",
      "*** L2 Distance ***\n",
      "Mean =  0.618309503591\n",
      "Max =  0.764415438053\n",
      "Min =  0.45088708081\n"
     ]
    }
   ],
   "source": [
    "dist_score = doeMasterObj.lhsDistScore(matrix_created)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> “Print” command returns only the mean distance values of L1 and L2 norms <p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0049381515504587, 0.61830950359116932)\n"
     ]
    }
   ],
   "source": [
    "print dist_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>1.4 Input Distribution Types and functions <h4> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Available Distributions <h4> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_doeMaster.getInputDistributionTypes( )_**\n",
    "<p> There are two distributions available in this package. The distributions available and the way the parameters should be considered can be displayed by using the below function 'getInputDistributionTypes' <p>\n",
    "<p> If nothing is mentioned about the values associated with a given distribution, the function assumes the default values. <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Default</th>\n",
       "      <th>Defaults</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uniform</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>uniform</td>\n",
       "      <td>['uniform',minValue,maxValue]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['uniform',0,1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normal</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>norm</td>\n",
       "      <td>['norm',loc,scale]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['norm',0,1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name        Type  Keyword                     Parameters Default  \\\n",
       "0  Uniform  Continuous  uniform  ['uniform',minValue,maxValue]     NaN   \n",
       "1   Normal  Continuous     norm             ['norm',loc,scale]     NaN   \n",
       "\n",
       "          Defaults  \n",
       "0  ['uniform',0,1]  \n",
       "1     ['norm',0,1]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doeMasterObj.getInputDistributionTypes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>1.5 Applying Distribution to Matrix <h4> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_doeMaster.applyDistributionToMatrix(inMatrix,inDistribution)_**\n",
    "<p> This particular function takes the input matrix and multiply the columns of the matrix to the respective distribution given in the inDistribution <p>\n",
    "<p> The input parameters for this function are:<p>\n",
    "* inMatrix : The input matrix should be a unit hypercube, i.e., Input Matrix should be a unit matrix (with values between 0-1) to apply the distributions to the matrix. \n",
    "* inDistribution : The list of distributions that needs to be applied in such a way that ith distribution is applied to the ith input (i.e. ith column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform Distribution Applied with mean:0 and std :1\n",
      "Uniform Distribution Applied with min:3 and max :4\n",
      "Uniform Distribution Applied with min:0 and max :20\n"
     ]
    }
   ],
   "source": [
    "matrix_created_modified = doeMasterObj.applyDistributionToMatrix(matrix_created, inDistribution=[[\"norm\", 0,1],[\"uniform\",3,4],[\"uniform\",0,20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.14318554,   3.47897811,   6.45482211],\n",
       "       [ -0.51884875,   3.29022724,  12.8626231 ],\n",
       "       [  0.73183204,   3.88234796,  15.44192544]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_created_modified # The input matrix will be updated based on the distributions mentioned in the previous step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>1.7 Plot Matrix <h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_doeMaster.plotMatrix(inputMatrix,addGrid=False,nNewPoints = None)_**\n",
    "<p> This function helps in visualising the matrix in a two-dimensional space. Plot Matrix helps in visualising the points of a Matrix, by plotting them One on One with taking each column as a vector and the values associated with that vector as the values on an axis. It plots a one on one matrix.  <p>\n",
    "The input parameters to be given are:\n",
    "* inputMatrix : The matrix to be plotted\n",
    "* figsize : By default, the plot matrix considers the figure size to be (5,5). This can be adjusted based on the requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xba61e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doeMasterObj.plotMatrix(matrix_created, figsize = (7,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>1.8 Adding new rows (points) <h4> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_doeMaster.addNpointsLHS(inMatrix, m=none, method=none)_**\n",
    "<p> The existing matrix can be modified by adding the new rows to the matrix. There are two methods by which the new rows (points) can be added. One method is 'random' and other is 'center'. Either of these two can be considered while modifying the matrix. The number of roes that are to be added can be specified by using 'm' <p> \n",
    "<p> The input parameters for this function are given below:<p>\n",
    "* inMatrix : The existing matrix which is needed to be modified <p>\n",
    "* m        : The number of rows that needs to added to the existing matrix. By Default, it considers m = 1. <p>\n",
    "* method   : The methods to be used for generating the numbers. Two methods are available, 'random' and 'center', are available in the package<p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.41666667  0.58333333  0.41666667]\n",
      " [ 0.08333333  0.08333333  0.08333333]\n",
      " [ 0.91666667  0.75        0.91666667]]\n",
      "[[ 0.91666667  0.75        0.41666667]\n",
      " [ 0.41666667  0.08333333  0.91666667]\n",
      " [ 0.08333333  0.58333333  0.08333333]]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "addNpoints_center = doeMasterObj.addNpointsLHS(matrix_created, m =3, method = 'center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.55692818  0.47897811  0.32274111]\n",
      " [ 0.30193311  0.29022724  0.64313116]\n",
      " [ 0.76786446  0.88234796  0.77209627]\n",
      " [ 0.91666667  0.75        0.41666667]\n",
      " [ 0.41666667  0.08333333  0.91666667]\n",
      " [ 0.08333333  0.58333333  0.08333333]]\n"
     ]
    }
   ],
   "source": [
    "print addNpoints_center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. pyDOEMaster <h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> doeMain contains class pyDOEMaster. An object has to be created first before calling the functions. Here, an object named \"pyDOEMasterObj\", we will use this object to access the functionality of the class.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from doeModule.doeMain import pyDOEMaster\n",
    "pyDOEMasterObj = pyDOEMaster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2.1 Creating LHS <h4> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_pyDOEMaster.lhs(nInputs=None,nSamples=None, inputDistribution = None,criterion = 'corr')_**\n",
    "<p> LHS is a method of generating the random samples of parameter values, from multi-dimensional distribution. It is pre-dominantly used in Monte Carlo Simulation. It reduces the number of runs required to achieve a reasonably accurate results. LHS is based on a Latin Square Design, in which there exists only a single sample in each row and column.<p> \n",
    "<p> The input parameters associated with this function are as listed below: <p>\n",
    "<p>* nInputs : The number of inputs required for LHS. It can be found across the columns of a given row.\n",
    "<p>* nSamples : The number of different samples required for LHS. It can be found across the rows of a given column. \n",
    "    * Inputs are displayed as the columns and the samples are displayed as the rows.\n",
    "<p>* inputDistribution : The distribution that needs to be applied across the samples. User needs to specify the type of the distribution, i.e. 'uniform' or 'norm', and the specifications associated with them. \n",
    "    * For Uniform, it is minimum value and the maximum value.\n",
    "    * For Normal, it is Location parameter, i.e. mean and the scale parameter, i.e. Deviation from the mean. \n",
    "<p>* criterion : There are 4 criteria that are available for this parameter.\n",
    "    * c : Center the points within the sampling intervals\n",
    "    * m : It maximizes the minimum distance between points, but places the point in a randomized location within its interval\n",
    "    * cm : Same as 'm' but centred within the intervals\n",
    "    * corr : It minimizes the maximum correlation co-efficient. By default, corr is applied to the function.\n",
    "<p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Let's start by creating a simple LHS without any distributions mentioned. By default, the function considers the distribution to be 'uniform' with 0 and 1 as min and max values respectively. <h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new candidate solution found with max,abs corrcoef = 0.992845176563\n"
     ]
    }
   ],
   "source": [
    "LHS_simple = pyDOEMasterObj.lhs(nInputs = 3, nSamples =3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03941823,  0.63708146,  0.81146809],\n",
       "       [ 0.57056675,  0.87570867,  0.49824705],\n",
       "       [ 0.81984203,  0.26391208,  0.19747585]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LHS_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> We can create the LHS, by mentioning the type of the distribution, that an Input should possess across its sample. There are two distributions associated with LHS, normal and uniform, as mentioned above <p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new candidate solution found with max,abs corrcoef = 0.552180422644\n",
      "Uniform Distribution Applied with min:5 and max :7\n",
      "Uniform Distribution Applied with mean:2 and std :3\n",
      "Uniform Distribution Applied with min:6 and max :19\n",
      "Uniform Distribution Applied with min:1 and max :4\n"
     ]
    }
   ],
   "source": [
    "LHS = pyDOEMasterObj.lhs(nInputs = 4, nSamples = 3, inputDistribution = [['uniform', 5,7],['norm', 2,3],['uniform', 6,19],['uniform', 1,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.69641225  -0.99661659  11.49966728   2.47448325]\n",
      " [  5.77970073   7.1506186    6.71486394   1.81073126]\n",
      " [  5.47405134   1.88553233  18.60682845   3.03020754]]\n"
     ]
    }
   ],
   "source": [
    "print LHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform Distribution Applied with min:5 and max :7\n",
      "Uniform Distribution Applied with mean:2 and std :3\n",
      "Uniform Distribution Applied with min:6 and max :19\n",
      "Uniform Distribution Applied with min:1 and max :4\n"
     ]
    }
   ],
   "source": [
    "LHS_criteria = pyDOEMasterObj.lhs(nInputs = 4, nSamples = 3, inputDistribution = \n",
    "                               [['uniform', 5,7],['norm', 2,3],['uniform', 6,19],['uniform', 1,4]], criterion = 'cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.66666667,   4.9022647 ,  12.5       ,   1.5       ],\n",
       "       [  6.        ,  -0.9022647 ,   8.16666667,   2.5       ],\n",
       "       [  5.33333333,   2.        ,  16.83333333,   3.5       ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LHS_criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Diversipy Master <h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> doeMain contains class diversipyMaster. \"diversipyMasterObj\" has been created to use the class functions <p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from doeModule.doeMain import diversipyMaster\n",
    "diversipyMasterObj = diversipyMaster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>3.1 Converting Co-ordinates To Unit Hypercube <h4> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_diversipyMaster.convertCoordinateToUnitHypercube(inMatrix,method='center')_**\n",
    "<p> This function helps in transforming the design space into Unit Hyper cube. <p> \n",
    "The input parameters are:<p>\n",
    "* inputMatrix: The matrix which needs to be converted\n",
    "* method: There are 3 methods associated with this \n",
    "    * center: Each point is placed at the centroid of a sub cell in the assumed grid over the cube. By Default, 'center' would be considered. \n",
    "    * random: Applies random perturbations so that each point is distributed randomly uniform in its grid cell. This is the variant proposed by McKay 1979.\n",
    "    * max_distance: The transformation is so that each face of the hypercube is sampled by at least one point (exactly one point in the case of LHDs). Use this transformation if you want to maximize the minimal distance between points in the design.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Convert_to_UH_center = diversipyMasterObj.convertCoordinateToUnitHypercube(matrix_created, method = 'center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35230939,  0.32632604,  0.27424704],\n",
       "       [ 0.26731104,  0.26340908,  0.38104372],\n",
       "       [ 0.42262149,  0.46078265,  0.42403209]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Convert_to_UH_center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>3.2 Creating LHD Matrix <h4> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**diversipyMaster.lhd_matrix(nInputs=None,nSamples=None, inputDistribution = None,selectPointMethod = 'center')**\n",
    "<p> It generates a random Latin hypercube design matrix. <p>\n",
    "<p> Latin hypercube designs sometimes give an advantage over random uniform samples due to their perfect uniformity of one-dimensional projections. <p> \n",
    "<p> The input parameters are given as mentioned below<p>\n",
    "* nInputs : The number of inputs required for LHS. It can be found across the columns of a given row.\n",
    "* nSamples : The number of samples of the given input required for LHS. It can be found across the rows of a given row.\n",
    "* inputDistribution: What type of the distribution to be applied on the input. The distribution is multiplied across the rows for a given column.\n",
    "* selectPointMethod : 3 methods are available. They are 'center', 'random' and 'max_distance'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Let's start with creating a simple Latin Hypercube Design Matrix as given below. If no distribution is mentioned, by default it considers a \"uniform\" distribution with 0 and 1 as minimum and maximum values <p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lhd_simple = diversipyMasterObj.lhd_matrix(nInputs =3, nSamples =3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5       ,  0.83333333,  0.83333333],\n",
       "       [ 0.16666667,  0.5       ,  0.16666667],\n",
       "       [ 0.83333333,  0.16666667,  0.5       ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lhd_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> The distributions can be applied while creating LHD as given below. <p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform Distribution Applied with mean:0 and std :1\n",
      "Uniform Distribution Applied with mean:5 and std :1\n",
      "Uniform Distribution Applied with min:4 and max :6\n"
     ]
    }
   ],
   "source": [
    "lhd_distribution = diversipyMasterObj.lhd_matrix(nInputs = 3, nSamples = 3, inputDistribution =[['norm',0,1],['norm',5,1],['uniform',4,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  4.03257843,  4.33333333],\n",
       "       [-0.96742157,  5.        ,  5.        ],\n",
       "       [ 0.96742157,  5.96742157,  5.66666667]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lhd_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> LHDs creation by specifying select point method: <p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform Distribution Applied with mean:0 and std :1\n",
      "Uniform Distribution Applied with mean:5 and std :1\n",
      "Uniform Distribution Applied with min:4 and max :6\n"
     ]
    }
   ],
   "source": [
    "lhdMatrix_center = diversipyMasterObj.lhd_matrix(nInputs = 3, nSamples = 3, inputDistribution =[['norm',0,1],['norm',5,1],['uniform',4,6]],selectPointMethod = 'center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  5.96742157,  5.66666667],\n",
       "       [-0.96742157,  4.03257843,  5.        ],\n",
       "       [ 0.96742157,  5.        ,  4.33333333]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lhdMatrix_center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>3.3 Improving the LHD Matrix <h4> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**diversipyMaster.improved_lhd_matrix(nInputs=None, nSamples=None, inputDistribution=None,selectPointMethod = 'center', num_candidates=100, target_value=None)**\n",
    "<p>It generates an ‘improved’ Latin hypercube design matrix. <p>\n",
    "This implementation uses an aldiversipyMaster.improved_lhd_matrixgorithm with quadratic run time. It is a greedy construction heuristic starting with a randomly chosen point. In each iteration, many random candidates is evaluated by a criterion that considers a candidate’s distance to the previously chosen points. The best point according to this criterion is included in the LHD.\n",
    "<p> More information about this algorithm cab found at \"Wessing2015\" <p>\n",
    "Input Parameters associated with this function are:\n",
    "* nInputs : The number of inputs required for LHS. It can be found across the columns of a given row.\n",
    "* nSamples : The number of samples of the given input required for LHS. It can be found across the rows of a given row.\n",
    "* inputDistribution : What type of the distribution to be applied on the input. The distribution is multiplied across the rows for a given column. If no distribution is mentioned, a unit hypercube will be created with the samples derived out of a Uniform distribution.\n",
    "* selectPointMethod : 3 methods are available. They are 'center', 'random' and 'max_distance. By default, the function takes 'center' as the input parameter. \n",
    "* num_candidates : The number of random candidates considered for every point to be added to the LHD. The default value is 100. \n",
    "* target_value : The distance a candidate should ideally have to the already chosen points of the LHD. \n",
    "\n",
    "<p> Let's start by applying this function in a very simple case, i.e., only with the number of inputs and samples. <p>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16666667,  0.16666667,  0.16666667],\n",
       "       [ 0.5       ,  0.5       ,  0.5       ],\n",
       "       [ 0.83333333,  0.83333333,  0.83333333]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diversipyMasterObj.improved_lhd_matrix(nInputs = 3, nSamples = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Applying the distributions when creating the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform Distribution Applied with mean:0 and std :1\n",
      "Uniform Distribution Applied with min:0 and max :4\n",
      "Uniform Distribution Applied with mean:12 and std :16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.96742157,   3.33333333,  12.        ],\n",
       "       [  0.        ,   2.        ,  27.47874506],\n",
       "       [ -0.96742157,   0.66666667,  -3.47874506]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diversipyMasterObj.improved_lhd_matrix(nInputs = 3, nSamples = 3,inputDistribution = [['norm',0,1],['uniform',0,4],['norm',12,16]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> LHDs creation by specifying select point method: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform Distribution Applied with mean:0 and std :1\n",
      "Uniform Distribution Applied with min:0 and max :4\n",
      "Uniform Distribution Applied with mean:12 and std :16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -0.99044325,   3.78740911,  16.81299826],\n",
       "       [  0.03839001,   1.80825512,  25.23051511],\n",
       "       [  0.82381487,   0.44648158,   3.17400326]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diversipyMasterObj.improved_lhd_matrix(nInputs = 3, nSamples = 3, inputDistribution = [['norm',0,1],['uniform',0,4],['norm',12,16]],selectPointMethod = 'random') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Adding the additional input parameter which considers the number of random candidates considered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform Distribution Applied with mean:0 and std :1\n",
      "Uniform Distribution Applied with min:0 and max :4\n",
      "Uniform Distribution Applied with mean:12 and std :16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.49208706,   3.91793392,  25.20011008],\n",
       "       [ -0.42181031,   1.94562118,   8.76180501],\n",
       "       [ -1.21626381,   1.02421435,   5.02862036]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diversipyMasterObj.improved_lhd_matrix(nInputs = 3, nSamples = 3, inputDistribution = [['norm',0,1],['uniform',0,4],['norm',12,16]],selectPointMethod = 'random', num_candidates = 25) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Adding the one more input parameter which considers the target value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform Distribution Applied with mean:0 and std :1\n",
      "Uniform Distribution Applied with min:0 and max :4\n",
      "Uniform Distribution Applied with mean:12 and std :16\n"
     ]
    }
   ],
   "source": [
    "Improved_LHD = diversipyMasterObj.improved_lhd_matrix(nInputs = 3, nSamples = 3, inputDistribution = [['norm',0,1],['uniform',0,4],['norm',12,16]],selectPointMethod = 'random', num_candidates = 25, target_value = 43.24) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.24957063,   2.97239487,  -2.75949413],\n",
       "       [  0.66852651,   1.92591881,   5.82324255],\n",
       "       [ -1.25385972,   0.94631089,  28.84732111]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Improved_LHD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>3.4 Sliced LHS Matrix <h4> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**diversipyMaster.slicedLHS(nInputs=None, nSamples=None, nSlice=2, inputDistribution=None,selectPointMethod = 'center', num_candidates=100, target_value=None)**\n",
    "<p> This function creates a sliced LHS using diversipy Libraries. <p>\n",
    "The input parameters to be given are:\n",
    "* nInputs : The number of inputs required for LHS. It can be found across the columns of a given row.\n",
    "* nSamples : The number of different samples required for LHS. It can be found across the rows of a given column. \n",
    "    * Inputs are displayed as the columns and the samples are displayed as the rows.\n",
    "* nSlice : Number of slices user wants to create. By default, it will be two. \n",
    "* inputDistribution : The distribution that needs to be applied across the samples. User needs to specify the type of the distribution, i.e. 'uniform' or 'norm', and the specifications associated with them. \n",
    "    * For Uniform, it is minimum value and the maximum value.\n",
    "    * For Normal, it is Location parameter, i.e. mean and the scale parameter, i.e. Deviation from the mean. \n",
    "* selectPointMethod : 3 methods are available. They are 'center', 'random' and 'max_distance. By default, the function takes 'center' as the input parameter. \n",
    "* num_candidates : The number of random candidates considered for every point to be added to the LHD. The default value is 100. \n",
    "* target_value : The distance a candidate should ideally have to the already chosen points of the LHD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform Distribution Applied with mean:0 and std :1\n",
      "Uniform Distribution Applied with min:0 and max :4\n",
      "Uniform Distribution Applied with mean:12 and std :16\n",
      "Uniform Distribution Applied with min:0 and max :10\n",
      "Uniform Distribution Applied with mean:0 and std :1\n",
      "Uniform Distribution Applied with min:0 and max :4\n",
      "Uniform Distribution Applied with mean:12 and std :16\n",
      "Uniform Distribution Applied with min:0 and max :10\n",
      "Uniform Distribution Applied with mean:0 and std :1\n",
      "Uniform Distribution Applied with min:0 and max :4\n",
      "Uniform Distribution Applied with mean:12 and std :16\n",
      "Uniform Distribution Applied with min:0 and max :10\n"
     ]
    }
   ],
   "source": [
    "Sliced_LHS = diversipyMasterObj.slicedLHS(nInputs = 4, nSamples = 3, nSlice = 3,inputDistribution = [['norm',0,1],['uniform',0,4],['norm',12,16], ['uniform',0,10]],selectPointMethod = 'center', num_candidates = 25, target_value = 43.24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Slice_1': array([[ 0.05555556,  0.61111111,  0.5       ,  0.38888889],\n",
       "        [ 0.72222222,  0.38888889,  0.16666667,  0.5       ],\n",
       "        [ 0.94444444,  0.83333333,  0.83333333,  0.94444444]]),\n",
       " 'Slice_2': array([[ 0.5       ,  0.05555556,  0.61111111,  0.61111111],\n",
       "        [ 0.61111111,  0.94444444,  0.94444444,  0.27777778],\n",
       "        [ 0.16666667,  0.72222222,  0.27777778,  0.72222222]]),\n",
       " 'Slice_3': array([[ -0.5894558 ,   1.11111111,   7.48454165,   8.33333333],\n",
       "        [  0.96742157,   0.66666667,  21.43129277,   0.55555556],\n",
       "        [ -0.28221615,   2.        , -13.49150109,   1.66666667]])}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sliced_LHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>4. Dakota Master <h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>doeMain contains another class \"dakotaMaster\". An object has to be created first before accessing the functions of the respective class. Here, an object called \"dakota_master\" has been created, which is assigned to the class \"dakotaMaster\" of \"doeMain_modified\" package. All the functions belonging to the respective class are called using this object.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from doeModule.doeMain import dakotaMaster\n",
    "dakotaMasterObj = dakotaMaster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>4.1 LHS <h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_dakotaMaster.lhs(nInputs=None, nSamples=None, inputDistribution=None,useLastSeed= False,addDiscreteVars=[ ])_**\n",
    "<p> This function calls the LHS method from the dakota library and creates the DOE based on that. It also helps in slicing down the matrices <p> \n",
    "<p> The input parameters to be given are as mentioned below:\n",
    "* nInputs: The number of inputs required for creating the LHS matrix. These inputs are displayed across the columns of a given row(sample). \n",
    "* nSamples: The total number of samples that needs to be created for the inputs. These samples are displayed across the rows of a given column.\n",
    "* inputDistribution: The distribution function that can be applied across the given sample while obtaining LHS Matrix. The available distributions are normal and uniform. These distributions can be applied as listed below:\n",
    "    * For Uniform: Distribution, minimum value, maximum value\n",
    "        * e.g. ['uniform', 0,1]\n",
    "    * For Normal: Distribution, Location parameter, Scale parameter. Location and Scale Parameters refer to mean and deviation from the mean respectively. \n",
    "        * e.g. ['norm',20,1]\n",
    "* useLastSeed : If you want to use the same seed value as used in last run, mention it as True.\n",
    "* addDiscreteVars : Should be a list, which sub lists all the possible values of the discreate variable. \n",
    "    * Eg: [['high', 'low', 'medium']\n",
    "\n",
    "<p> This is in one of the ways of creating LHS <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Let's start by creating a simple LHS using Dakota Master <p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed = 15674\n"
     ]
    }
   ],
   "source": [
    "dakota_lhs = dakotaMasterObj.lhs(nInputs = 3, nSamples = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00637299,  0.54562848,  0.69959154],\n",
       "       [ 0.92788745,  0.30188789,  0.56713406],\n",
       "       [ 0.54504183,  0.79743921,  0.22318026]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dakota_lhs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Applying Distribution to the obtained matrix <p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform Distribution Applied with min:2 and max :6\n",
      "Uniform Distribution Applied with mean:0 and std :1\n",
      "Uniform Distribution Applied with min:8 and max :10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.02549194,  0.11462414,  9.39918309],\n",
       "       [ 5.71154979, -0.51897844,  9.13426812],\n",
       "       [ 4.18016731,  0.83250922,  8.44636051]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dakotaMasterObj.applyDistributionToMatrix(dakota_lhs, [['uniform', 2,6],['norm', 0,1],['uniform',8,10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Distributions can be applied during the creation of LHS rather than after creating a LHS as shown below <p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed = 15674\n",
      "Uniform Distribution Applied with mean:20 and std :1\n",
      "Uniform Distribution Applied with min:0 and max :1\n",
      "Uniform Distribution Applied with min:10 and max :15\n"
     ]
    }
   ],
   "source": [
    "LHS = dakotaMasterObj.lhs(nInputs = 3, nSamples = 3, inputDistribution =[['norm',20,1],['uniform', 0,1],['uniform',10,15]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 17.50921078   0.54562848  13.49795772]\n",
      " [ 21.46023643   0.30188789  12.83567031]\n",
      " [ 20.11314406   0.79743921  11.11590129]]\n"
     ]
    }
   ],
   "source": [
    "print LHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<p> A LHS can also be created by using the discrete variables. These discrete variables should be at least two. The input parameters are given as mentioned below. <p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed = 15674\n",
      "Uniform Distribution Applied with mean:20 and std :1\n",
      "Uniform Distribution Applied with min:0 and max :1\n",
      "Uniform Distribution Applied with min:10 and max :15\n"
     ]
    }
   ],
   "source": [
    "LHS_withVars = dakotaMasterObj.lhs(nInputs =3, nSamples = 10, inputDistribution =[['norm',20,1],['uniform', 0,1],['uniform',10,15]],useLastSeed = True, addDiscreteVars=[[\"x\",'z'],[\"rainy\", \"snowy\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21.473675437748614, 0.6067620803, 12.955893074, 'x', 'rainy'],\n",
       "       [19.90885463503313, 0.8206513184, 10.2573721467, 'z', 'rainy'],\n",
       "       [20.73930870795537, 0.4633691744, 10.5880326905, 'x', 'snowy'],\n",
       "       [17.107656085056636, 0.5214208915999999, 11.406691339, 'x', 'snowy'],\n",
       "       [20.09849848765222, 0.09190503131000001, 13.7204192685, 'x', 'snowy'],\n",
       "       [19.722156808005217, 0.22276534239999998, 11.726915798, 'z', 'rainy'],\n",
       "       [20.43151789247521, 0.152449248, 12.297812643, 'z', 'snowy'],\n",
       "       [19.4122982012384, 0.9681176113, 14.391164727, 'z', 'snowy'],\n",
       "       [20.87744482821421, 0.7394265928, 14.776796938, 'x', 'rainy'],\n",
       "       [19.019876371544626, 0.3864024436, 13.2432719365, 'z', 'rainy']], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LHS_withVars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21.473675437748614 0.6067620803 12.955893074 'x' 'rainy']\n",
      " [19.90885463503313 0.8206513184 10.2573721467 'z' 'rainy']\n",
      " [20.73930870795537 0.4633691744 10.5880326905 'x' 'snowy']\n",
      " [17.107656085056636 0.5214208915999999 11.406691339 'x' 'snowy']\n",
      " [20.09849848765222 0.09190503131000001 13.7204192685 'x' 'snowy']\n",
      " [19.722156808005217 0.22276534239999998 11.726915798 'z' 'rainy']\n",
      " [20.43151789247521 0.152449248 12.297812643 'z' 'snowy']\n",
      " [19.4122982012384 0.9681176113 14.391164727 'z' 'snowy']\n",
      " [20.87744482821421 0.7394265928 14.776796938 'x' 'rainy']\n",
      " [19.019876371544626 0.3864024436 13.2432719365 'z' 'rainy']]\n"
     ]
    }
   ],
   "source": [
    "print LHS_withVars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>4.2 Slicing LHS <h4> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_dakotaMaster.slicedLHS(nInputs=None, nSamples=None,nSlice=2, inputDistribution=None,useLastSeed= False)_**\n",
    "<p> This function creates the sliced LHS using the existing dakota functions. Sliced LHS is a design which is a special LHD that can be decomposed into smaller slices, each of which is an LHD.  This slicing idea is related to central composite designs for quantitative and qualitative factors\n",
    "The input parameters for Sliced LHS are as given below: \n",
    "* nInputs: The number of inputs required for creating the LHS matrix. These inputs are displayed across the columns of a given row(sample). \n",
    "* nSamples: The total number of samples that needs to be created for the inputs. These samples are displayed across the rows of a given column.\n",
    "* nSlice = Number of slices required. The number of slices should be in the integer form.\n",
    "* inputDistribution: The distribution function that can be applied across the given sample while obtaining LHS Matrix. The available distributions are normal and uniform. These distributions can be applied as listed below:\n",
    "    * For Uniform: Distribution, minimum value, maximum value\n",
    "        * e.g. ['uniform', 0,1]\n",
    "\n",
    "    * For Normal: Distribution, Location parameter, Scale parameter. Location and Scale Parameters refer to mean and deviation from the mean respectively.\n",
    "        * e.g. ['norm',20,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed = 15674\n",
      "Uniform Distribution Applied with mean:4 and std :5\n",
      "Uniform Distribution Applied with min:3 and max :6\n"
     ]
    }
   ],
   "source": [
    "Sliced_LHS = dakotaMasterObj.slicedLHS(nInputs = 2, nSamples = 3, nSlice =2, inputDistribution =[['norm',4,5],['uniform',3,6]], useLastSeed = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Slice_1': array([[7.740734776894426, 4.648577502],\n",
       "        [-9.639734801651535, 5.7622462398],\n",
       "        [0.9739677312675505, 3.3347703857999997]], dtype=object),\n",
       " 'Slice_2': array([[10.371448181983451, 5.4595251564],\n",
       "        [3.547484601803113, 4.0493873166],\n",
       "        [5.939350874545514, 3.850701093]], dtype=object)}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sliced_LHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed = 15674\n",
      "Uniform Distribution Applied with mean:20 and std :1\n",
      "Uniform Distribution Applied with min:0 and max :1\n",
      "Uniform Distribution Applied with min:10 and max :15\n"
     ]
    }
   ],
   "source": [
    "Sliced_LHS = dakotaMasterObj.slicedLHS(nInputs = 3, nSamples = 3, nSlice =2, inputDistribution =[['norm',20,1],['uniform', 0,1],['uniform',10,15]], useLastSeed = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Slice_1': array([[17.272053039669693, 0.11159012859999999, 12.67850743],\n",
       "        [21.27428963639669, 0.34979577219999997, 13.389684003],\n",
       "        [19.39479354625351, 0.9207487466, 10.1897111865]], dtype=object),\n",
       " 'Slice_2': array([[19.909496920360624, 0.8198417188, 14.4952216065],\n",
       "        [20.748146955378886, 0.549525834, 12.1947431205],\n",
       "        [20.387870174909104, 0.283567031, 11.5533536965]], dtype=object)}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sliced_LHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Slicing the LHS by considering the discrete variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed = 15674\n",
      "Uniform Distribution Applied with mean:20 and std :1\n",
      "Uniform Distribution Applied with min:0 and max :1\n",
      "Uniform Distribution Applied with min:10 and max :15\n"
     ]
    }
   ],
   "source": [
    "Sliced_LHS = dakotaMasterObj.slicedLHS(nInputs = 3, nSamples = 3, nSlice =2, inputDistribution =[['norm',20,1],['uniform', 0,1],['uniform',10,15]], useLastSeed = True, addDiscreteVars =[['high','low'],['rainy','snowy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Slice_1': array([[19.909496920360624, 0.9207487466, 12.1947431205],\n",
       "        [20.748146955378886, 0.11159012859999999, 13.389684003],\n",
       "        [21.27428963639669, 0.8198417188, 14.4952216065]], dtype=object),\n",
       " 'Slice_2': array([[20.387870174909104, 0.283567031, 10.1897111865],\n",
       "        [19.39479354625351, 0.549525834, 11.5533536965],\n",
       "        [17.272053039669693, 0.34979577219999997, 12.67850743]], dtype=object),\n",
       " 'high': array([[20.387870174909104, 0.283567031, 10.1897111865],\n",
       "        [19.909496920360624, 0.9207487466, 12.1947431205],\n",
       "        [20.748146955378886, 0.11159012859999999, 13.389684003]], dtype=object),\n",
       " 'low': array([[19.39479354625351, 0.549525834, 11.5533536965],\n",
       "        [17.272053039669693, 0.34979577219999997, 12.67850743],\n",
       "        [21.27428963639669, 0.8198417188, 14.4952216065]], dtype=object),\n",
       " 'rainy': array([[20.387870174909104, 0.283567031, 10.1897111865],\n",
       "        [19.909496920360624, 0.9207487466, 12.1947431205],\n",
       "        [19.39479354625351, 0.549525834, 11.5533536965]], dtype=object),\n",
       " 'snowy': array([[17.272053039669693, 0.34979577219999997, 12.67850743],\n",
       "        [20.748146955378886, 0.11159012859999999, 13.389684003],\n",
       "        [21.27428963639669, 0.8198417188, 14.4952216065]], dtype=object)}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sliced_LHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>4.3 Orthogonal Array Latin Hypercube Sample <h4> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_dakotaMaster.oaLHS(nInputs=None, nSamples=None, inputDistribution=None, useLastSeed=False, addDiscreteVars=[ ])_**\n",
    "<p> This function creates the Orthogonal Array Latin Hyper Cube Sample. OA-LHS is a hybrid design which is combination of an orthogonal array and a Latin Hypercube sample. This design has the advantages of both orthogonality of the inputs as well as stratification of the samples. <p>\n",
    "<p> The input parameters for this OA-LHS is:<p>\n",
    "* nInputs : The number of inputs required for LHS. It can be found across the columns of a given row.\n",
    "* nSamples : The number of samples of the given input required for LHS. It can be found across the rows of a given row.\n",
    "* inputDistribution : What type of the distribution to be applied on the input. The distribution is multiplied across the rows for a given column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nSamples updated to :  4\n",
      "Seed = 15674\n",
      "Uniform Distribution Applied with mean:20 and std :5\n",
      "Uniform Distribution Applied with min:5 and max :6\n"
     ]
    }
   ],
   "source": [
    "OA_LHS = dakotaMasterObj.oaLHS(nInputs = 2, nSamples =3, inputDistribution =[['norm',20,5],['uniform',5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 19.47915624,   5.76077303],\n",
       "       [ 23.54395702,   5.61507767],\n",
       "       [ 11.12273856,   5.03791162],\n",
       "       [ 21.46289046,   5.45851772]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OA_LHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>4.4 Incremental LHS <h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_dakotaMaster.incrementalLHS( )_**\n",
    "<p> This can be used only if the DOE is created using a Dakota Library. It can't be used if we have discrete variables in DOE. Any of the DakotaLHS methoda have to be ran just before to it<p> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Incremental_LHS = dakotaMasterObj.incrementalLHS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.69591559,  0.15922136],\n",
       "       [ 0.40878137,  0.34807941],\n",
       "       [ 0.97641592,  0.92535055],\n",
       "       [ 0.00477974,  0.66738519],\n",
       "       [ 0.19419923,  0.38195502],\n",
       "       [ 0.53092075,  0.07482679],\n",
       "       [ 0.28147269,  0.61578794],\n",
       "       [ 0.84987791,  0.78360461]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Incremental_LHS"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
